<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>零代码查看重复文件的小妙招</title>
    <link href="/techlife/tip-check-duplicate-file.html"/>
    <url>/techlife/tip-check-duplicate-file.html</url>
    
    <content type="html"><![CDATA[<blockquote style="font-size: 14px;color: White; background-color: darkslategray; padding: 15px; border-radius: 10px; outline: 2px dotted darkslategray; outline-offset: 5px;">    <b style="font-size: 16px;">TL;DR</b>    <br>    要检查的文件放到同一级文件里，全选压缩成压缩文件。然后用 WinRAR 双击打开，如果 CRC32 相同则为同一文件。</blockquote><br><div style="text-align: center; font-size: 16px; color: gray;">    · · · · · ✦ ✧ ✦ · · · · ·</div><br><p>之前做一个物体检测模型，在数据收集阶段遇到一个令人头大的小问题。当时用的是 GCP (Google Cloud Platform) 的低代码模型训练平台 AutoML，把图片上传到平台可以进行人工标注。平台要求每一种物体至少上传 10 张图片才能执行训练任务，基于这个数量要求我定的数据需求是在同一个位置拍摄 10 张图片。我考虑到前线人员的工作量，所以并没有要求从不同角度拍摄，只要把相关物体都拍到就可以了，站在同一个位置连续按 10 次照相机就可以完成。</p><p>即使要求已经很低了，但还是有自作聪明的懒人，拍了 1 张图片然后复制 9 张，改了名字就发过来交差。重复图片上传到 AutoML 会自动去重，也就是说我收集到 10 张图片，上传成功的只有 1 张。批量上传图片所需费时，需要等图片全部上传完才知道有重复图片被去重了。图片数量繁多，而且我并没有要求从不同角度拍摄，所以考虑从相似图片来手动剔除再上传是很难实现的。我必需解决这个费时费力的小问题。</p><p>那时候还没有 ChatGPT，当然我现在尝试了问 ChatGPT，也是给了我几个差不多的方案。一是查哈希值。每张图片有唯一的哈希值，如果哈希值一样代表是同一张图片。怎么查哈希值呢？在电脑终端写命令，或者是写 Python 调包。二是下载软件。</p><p>正打算找个 Python 代码来批量读哈希值呢，在整理图片的时候忽然另辟蹊径发现了一个另类的方式。用 WinRAR 这个压缩软件打开包含多张图片的压缩包，可以看到一列信息叫 <b  style="color: tomato;">CRC32</b>。</p><p><img src="/img/2025-07-25-winrar-check-duplicates/winrar.png"></p><p>上图第二张图片 <i  style="color: violet;">copy.jpg</i> 是第一张图片复制的副本，可以看到它俩的 CRC32 是一样的。那么把所有图片放到一起压缩，再用 WinRAR 打开，CRC32 按序排列就可以查看有哪些图片是重复的。我就不用等图片在平台上传完才知道又缺哪些位置的图片了。这样不用写代码，也不用另外下载工具，问题解决！</p><blockquote style="padding: 15px; border-radius: 10px; border-left: none; outline: 3px dotted darkslategray;">    <b style="color: tomato;">什么是 CRC32</b>    <br>    CRC（Cyclic Redundancy Check），循环冗余校验，用来快速检查数据内容有没有变化。CRC32 是 CRC 算法的一种具体实现，输出固定为 32 位（通常以 8 位十六进制显示），常见于以太网帧（Ethernet FCS）、ZIP、PNG、GZIP 等格式。</blockquote><p>所以，除了图片，其他类型的文件也可以用这种方式来查看是否重复。<br><img src="/img/2025-07-25-winrar-check-duplicates/winrar1.png"><br>比如我们有一个原始的 Word 文档 <i  style="color: violet;">测试word.docx</i>，复制了 2 个副本，其中 <i  style="color: violet;">测试word - 副本.docx</i> 不做任何改动，<i  style="color: violet;">测试word - 副本 (2).docx</i> 改动了内容再保存。可以看到没做改动的文件和原文件的 CRC32 值是一样的，而改动过的文件 CRC32 值就变了。</p>]]></content>
    
    
    <categories>
      
      <category>Tech &amp; Life</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>RAG架构💫源于AI，不只AI</title>
    <link href="/techlife/rag-concept.html"/>
    <url>/techlife/rag-concept.html</url>
    
    <content type="html"><![CDATA[<blockquote style="font-size: 14px;color: White; background-color: darkslategray; padding: 15px; border-radius: 10px; outline: 2px dotted darkslategray; outline-offset: 5px;">    <b style="font-size: 16px;">TL;DR</b>    <ul style="margin: 10px 0; padding-left: 1.5em;">        <li>影响 RAG 最终效果的不止底层的 LLM，还有 retrieve（检索）结果，如果检索结果没有找对，LLM 再厉害也得不到理想的回答。</li>        <li>不同的 chunking 会影响 retrieve 结果，如何选择 chunking 策略是一个不小的挑战。</li>        <li>最大的工作量不是在 RAG 流程搭建，而是在 chunking 和 retrieve 的策略选择。</li>    </ul></blockquote><br><div style="text-align: center; font-size: 16px; color: gray;">    · · · · · ✦ ✧ ✦ · · · · ·</div><br><p>如前文《<a href="/techlife/llm-application-basic.html" title="LLM应用💫不需要学AI，会调接口就行">LLM应用💫不需要学AI，会调接口就行</a>》所说，AI 对话产品中的“联网搜索”是通过检索来优化 LLM 的生成结果，这种技术架构称为 <strong>RAG（Retrieval-Augmented Generation，检索增强生成）</strong>。现在 RAG 在业界十分常见，用于搭建基于私有知识库的 AI 场景。通过检索从企业或个人的私有知识库中提取相关信息，结合 LLM 进行生成，有效保证内容的专业性和私密性。</p><h1 id="1-Retrieve（检索）"><a href="#1-Retrieve（检索）" class="headerlink" title="1. Retrieve（检索）"></a>1. Retrieve（检索）</h1><p>在 RAG 架构中，检索环节是核心步骤，决定了生成内容的相关性和准确性。“联网搜索”功能中，数据源就是互联网数据，检索方式就是搜索引擎，直接调用搜索引擎 API 就可以解决了。那么我们的数据源换成私有知识库，检索又如何实现呢？</p><h2 id="1-1-检索策略"><a href="#1-1-检索策略" class="headerlink" title="1.1. 检索策略"></a>1.1. 检索策略</h2><p>当前很常用的检索策略是 <span style="color:orange;"><strong>Hybrid search（混合搜索）</strong></span>。Hybrid search 是指 <u>Lexical search（词汇搜索）</u>和 <u>Semantic search（语义搜索）</u>两种搜索类别的结合。</p><h3 id="1-1-1-Lexical-search（词汇搜索）"><a href="#1-1-1-Lexical-search（词汇搜索）" class="headerlink" title="1.1.1. Lexical search（词汇搜索）"></a>1.1.1. Lexical search（词汇搜索）</h3><p><span style="color:orange;"><strong>Lexical search（词汇搜索）</strong></span>，主要技术有 <span style="color:violet;">Keyword search（关键词搜索）</span>和 <span style="color:violet;">Full-text search（全文搜索）</span>。Keyword search（关键词搜索），顾名思义是找到精准匹配的关键词。而 Full-text search（全文搜索）可以看作是在关键词匹配的基础上，引入了部分传统 NLP 技术（不包括深度学习），从而支持模糊匹配和更灵活的检索。</p><p>词汇搜索的应用很常见：</p><ul><li>电商平台搜索产品（例如在淘宝搜扫地机器人可以找到相关的商品）</li><li>博客或知识库全文中搜索明确关键词（例如在本站搜 RAG 可以找到包含这个词语的文章）</li><li>图书馆系统里搜索书名</li></ul><p>显然词汇搜索有一定的局限性，它<i style="color:tomato;">无法找到同义词、无法理解上下文、拼写错误会影响搜索结果</i>。而 Semantic search（语义搜索）可以补足词汇搜索的这些缺点。</p><h3 id="1-1-2-Semantic-search（语义搜索）"><a href="#1-1-2-Semantic-search（语义搜索）" class="headerlink" title="1.1.2. Semantic search（语义搜索）"></a>1.1.2. Semantic search（语义搜索）</h3><p><span style="color:orange;"><strong>Semantic search（语义搜索）</strong></span>，在当前 RAG 架构主要就是使用 <span style="color:violet;">Vector search（向量搜索）</span>。</p><h4 id="Embedding（文本向量化）"><a href="#Embedding（文本向量化）" class="headerlink" title="Embedding（文本向量化）"></a>Embedding（文本向量化）</h4><p>先把文本转化成向量表示，称为 embedding（文本向量化），向量里包含了语义信息。再计算两个文本的向量距离（相似度），就可以判断它们是否相似。我们只需要知道，把文本用向量来表示是包含语义的，做向量检索就可以匹配到语义相近的文本。各厂商有提供 embedding 模型的接口，直接调用即可。比如调用 <a href="https://platform.openai.com/docs/guides/embeddings/embedding-models">OpenAI - Embeddings</a>，传入一个文本可以得到一个1536维度的数组。</p><p>假设我们的知识库是所有 helpdesk 工单，每个单的文本做 embedding 变成向量存储到数据库里。我们想要搜索和新工单语义最接近的 5 个单，那就把新工单做 embedding 变成一个向量，计算这个向量和数据库里所有向量的距离，相似度最高的 5 个就是我们要找的单。</p><p><img src="/img/2025-07-09-rag-basic/helpdesk_vector_search.png"></p><p>注意，请求搜索的文本做 embedding 时选用的模型，必须与数据库中向量化所使用的模型一致。因为不同模型生成的向量完全不同，不同 embedding 模型之间不能通用。如果要更换 embedding 模型，需要把数据库中已存储的数据重新做 embedding 写入。</p><p>✨ <i style="font-size: 12px;">embedding 模型的好坏会影响检索结果。我认为一般来说已经发布的模型效果不会太差，我会选择当前最新且价格不高的模型。OpenAI 的第三代 embedding 模型 <code>text-embedding-3-large</code> 和 <code>text-embedding-3-small</code> 支持多语言，比之前第二代的 <code>text-embedding-ada-002</code> 只用了英文来训练的效果更好，是个不错的选择。</i></p><p>语义搜索看起来好像比词汇搜索更高级，但也存在不足，它<i style="color:tomato;">不能识别新词和低频词</i>，而这些用词汇搜索是可以实现的。两者互补，使得“词汇搜索+语义搜索”这种既要又要的混合搜索方式成为 RAG 技术栈中的主流。</p><h3 id="1-1-3-Hybrid-search（混合搜索）"><a href="#1-1-3-Hybrid-search（混合搜索）" class="headerlink" title="1.1.3. Hybrid search（混合搜索）"></a>1.1.3. Hybrid search（混合搜索）</h3><blockquote style="padding: 15px; border-radius: 10px; border-left: none; outline: 3px dotted darkslategray;">    <b style="color: orange;">Hybrid search = Lexical search + Semantic search</b>    <ul style="margin: 10px 0; padding-left: 1.5em;">        <li><b>Lexical search</b>（词汇搜索，如关键词搜索、全文搜索、……）            <ul>                <li>优：匹配精准、支持新词/罕见词、能识别拼写精确的查询</li>                <li>劣：缺乏语义理解、无法识别同义词、对拼写错误敏感</li>            </ul>        </li>        <li><b>Semantic search</b>（语义搜索，如向量搜索、……）            <ul>                <li>优：理解上下文含义、支持模糊匹配、能识别表达差异的相似内容</li>                <li>劣：无法识别新词/低频词、对精确查询不敏感、依赖模型一致性</li>            </ul>        </li>    </ul></blockquote><p>✨ <i style="font-size: 12px;">理论上混合搜索是最佳选择，但实际应用中有可能只用词汇搜索或者只用向量搜索就可以达到类似的效果，使用单一的检索策略可以节省资源。使用不同的策略对检索效果的差异取决于具体任务的数据特性和查询需求。我会直接闭眼选择混合搜索。</i></p><h2 id="1-2-Reranking（重排）"><a href="#1-2-Reranking（重排）" class="headerlink" title="1.2. Reranking（重排）"></a>1.2. Reranking（重排）</h2><p>即使使用了混合搜索，但效果可能依然不佳。为了解决词汇搜索和语义搜索的局限性，在进行混合搜索后，又有对检索结果进行二次处理的策略—— reranking。从字面意思看就是重排，在进行初步检索后，训练一个模型来评估请求搜索的文本与每个候选项的匹配度，从而二次排序，得到更准确的结果。</p><p><strong>那做 reranking 和做 embedding 算相似度有什么不同呢？</strong></p><blockquote><p>按我的理解，我会把 <u><b>reranking</b> VS <b>vector search</b></u> 类比成 <u><b>因果推断</b> VS <b>相关性</b></u>。如果你没有统计学的背景，那么我举一个例子说明。</p><p><i style="font-size: 14px;">比如，夏天人们会吃更多的冰淇淋，也更容易晒伤。如果从数据上看，这两件事是正相关。但我们知道吃冰淇淋并不会导致晒伤，晒伤也不会反过来让人去吃冰淇淋。</i></p><p>这就好比 vector search 只能找到数据上算出来是有相关性的内容，而 reranking 进一步判断“这些候选项里，哪些是和用户的问题真正相关的”。</p></blockquote><p><strong>reranking 是如何改善检索效果呢？</strong></p><blockquote>  <p style="font-size: 12px;">（以下为虚拟案例说明 reranking 机制达到的理想效果。）</p>  比如用户查询：<span style="color: Violet;">“法律援助如何申请”</span>  <br>  <br><div style="font-size: 12px;">  <p>初步检索返回的 top 5 结果：</p>  <table border="1" cellspacing="0" cellpadding="4">    <thead>      <tr>        <th>rank</th>        <th>text</th>        <th>remark</th>      </tr>    </thead>    <tbody>      <tr>        <td>1</td>        <td>「中国法律体系包括民法、刑法、行政法等，是国家治理的基石之一。」</td>        <td>（语义有“法律”，但和“申请援助”无关）</td>      </tr>      <tr>        <td>2</td>        <td>「很多人不知道，他们在遇到法律问题时可以申请法律援助，这通常适用于收入较低的人群。」</td>        <td>（提到了“可以申请”，但没说如何申请）</td>      </tr>      <tr>        <td>3</td>        <td>「申请法律援助的第一步是前往当地司法局，填写申请表，并提交收入证明和案件材料。」</td>        <td>✅ （明确回答“如何申请”）</td>      </tr>      <tr>        <td>4</td>        <td>「在一些地区，法律援助可以通过线上平台提交申请，节省了大量时间。」</td>        <td>✅ （也在讲申请流程）</td>      </tr>      <tr>        <td>5</td>        <td>「法律援助制度的发展源于对社会公平正义的追求，其在许多国家已逐步制度化。」</td>        <td>（背景知识，有些远）</td>      </tr>    </tbody>  </table>  <p><br>reranking 后的结果（结合用户问题精准排序）：</p>  <table border="1" cellspacing="0" cellpadding="4">    <thead>      <tr>        <th>rerank</th>        <th>text</th>        <th>remark</th>      </tr>    </thead>    <tbody>      <tr>        <td>1</td>        <td>「申请法律援助的第一步是前往当地司法局，填写申请表，并提交收入证明和案件材料。」</td>        <td>✅ （明确回答“如何申请”）</td>      </tr>      <tr>        <td>2</td>        <td>「在一些地区，法律援助可以通过线上平台提交申请，节省了大量时间。」</td>        <td>✅ （也在讲申请流程）</td>      </tr>      <tr>        <td>3</td>        <td>「很多人不知道，他们在遇到法律问题时可以申请法律援助，这通常适用于收入较低的人群。」</td>        <td>（提到了“可以申请”，但没说如何申请）</td>      </tr>      <tr>        <td>4</td>        <td>「法律援助制度的发展源于对社会公平正义的追求，其在许多国家已逐步制度化。」</td>        <td>（背景知识，有些远）</td>      </tr>      <tr>        <td>5</td>        <td>「中国法律体系包括民法、刑法、行政法等，是国家治理的基石之一。」</td>        <td>（语义有“法律”，但和“申请援助”无关）</td>      </tr>    </tbody>  </table></div></blockquote><p>✨ <i style="font-size: 12px;">reranking 用于优化检索结果，需依赖更精确、计算量更大的模型，因此也会带来响应速度的下降。实际效果因场景而异，有时还可能起反效果。通常 reranking 会在初步检索出的 top 50-100 结果中进行。但如果数据量本就不大，或初步检索后的 top N 中已有不少无关项，引入 reranking 可能反而更累赘。</i></p><h2 id="1-3-交给-LLM-理解的检索结果并不是越多越好"><a href="#1-3-交给-LLM-理解的检索结果并不是越多越好" class="headerlink" title="1.3. 交给 LLM 理解的检索结果并不是越多越好"></a>1.3. 交给 LLM 理解的检索结果并不是越多越好</h2><p>或许你会想，检索结果不够准确，那把足够多的候选项塞给 LLM 去理解生成答案不就完美解决了。LLM 的 input token 能吃下多少就丢多少候选项进去，这样可以尽量减少信息的丢失。然而事实并非如此。</p><p>与 LLM 刚火起来时对比，现在很多 LLM 可以接纳的 input token 变得非常大，让人觉得传给模型的信息越多就能得到越好的效果。从我实际测试的效果来看，传入很长的检索结果（包含一些内容相关较弱的候选项）让 LLM 根据这一大堆内容来回答用户的提问，会降低回复的质量。有论文证实，LLM 在处理长文本时，对开头&#x2F;结尾的信息理解表现比较好，而位于中间的信息更容易被忽略。<sup id="fnref:1" class="footnote-ref"><a href="#fn:1" rel="footnote"><span class="hint--top hint--rounded" aria-label="[Lost in the Middle: How Language Models Use Long Contexts](https://arxiv.org/abs/2307.03172)">[1]</span></a></sup></p><p>所以提高检索结果的准确度，筛选出少量真正相关的候选项，对最终生成的回复非常重要。</p><h2 id="1-4-Vector-database（向量数据库）"><a href="#1-4-Vector-database（向量数据库）" class="headerlink" title="1.4. Vector database（向量数据库）"></a>1.4. Vector database（向量数据库）</h2><p>要实现以上所说的检索，Vector database（向量数据库）就进入了大众视野。现在有很多向量数据库可选，常见的有：Chroma &#x2F; FAISS &#x2F; Qdrant &#x2F; Milvus &#x2F; Pinecone &#x2F; Weaviate &#x2F; Elasticsearch &#x2F; PostgreSQL（+ pgvector插件）等等，还有 Azure 的 AI Search 服务和 Cosmos DB。</p><p>这些向量数据库都支持混合搜索，也可以选择只用词汇搜索或者只用向量搜索。使用向量数据库，无需自己写搜索算法，无需搞清楚两类搜索是怎么混合的，依照各自的文档实现即可。当然在混合搜索里也可以调整一些参数，比如两类搜索的权重，这就需要进一步了解混合搜索实现的细节了。</p><p>✨ <i style="font-size: 12px;">常见的向量数据库都有那么多种选择，可见没有哪一个是完全优于其他的。如何选择适合自己场景的向量数据库，需要基于具体任务对性能、价格和数据安全等多方面进行探索。</i></p><h1 id="2-Chunking（切分）"><a href="#2-Chunking（切分）" class="headerlink" title="2. Chunking（切分）"></a>2. Chunking（切分）</h1><p>Chunking，指的是长文本切分成多个长度较小的 chunk（块）。</p><p><strong>什么情况要做 chunking？</strong></p><blockquote><p>如果要处理的是如 helpdesk 工单、OA 工单、报修工单等这类工单类型的数据，本身文本长度就很短，就没有必要做 chunking。</p><p>如果要处理的是合同、项目报告、会议纪要、审计记录、内部知识库等长文本文档，有可能单个文档就很长，更不用说需要检索出多个候选项合并传给 LLM 了。这时候我们需要把文本内容切分成更小的 chunk，<span style="color:tomato;">一来可以满足 token 限制，二来可以提高检索的准确度</span>。</p></blockquote><p><strong>通用 chunking 策略？</strong></p><blockquote><p>没有标准通用的 chunking 策略。为了满足不同的需求，chunking 策略千差百异。</p><p>文档可以按页切分，按段落切分，按句子切分；还可以按文本长度切分，按 token 长度切分。</p><p>比如从长度上考虑，按页切分就可以解决 token 限制的问题，但如果我要做一个文档对话产品，想要它可以高亮引用句子，那么基于这个需求，就需要按句子切分。</p></blockquote><p><strong>chunking 难点？</strong></p><blockquote><p>如果切分打断了一个语义连贯的段落，会导致检索结果丢失相关信息。</p><p><i style="font-size: 14px;">比如文档内容是这样的：“<span style="color: gray; background-color: #f4d03f;">…… 以下是第一季度房地产市场的整体表现。</span><span style="color: gray; background-color: #58d68d;">该季度一线城市成交量同比增长12%，二线城市价格保持平稳，三线城市则出现轻微回落。……</span>”如果被切成 2 个 chunk。当用户提问：“第一季度房产市场的情况”，检索只会匹配到前一个 chunk，后一个 chunk 会被忽略，而后者才是我们需要的内容。</i></p><p>检索结果丢失了关键信息，那么即使 LLM 厉害到能上天也无法给出正确的答案。</p><p>为了解决 chunking 难题，衍生出五花八门的策略，比如 recursive chunking（初步切分后仍过长或不连贯时，递归寻找更合适的断点），设置前后两个 chunk 之间的文本重叠数量（有些句子或段落同时出现在前后两个 chunk 中），基于语义的切分（通过 embedding 判断语义变化点），等等。</p><p>LLM 领域一个常用的实现工具 LangChain，它的 <a href="https://python.langchain.com/docs/concepts/text_splitters/">Text splitters</a> 模块提供了以上所说的多种切分策略。但实际上并不能完全依赖于开源工具，比如我用高阶的工具识别出表格、图片这些特殊类型的内容，不希望这些内容块被切开，就不能直接使用开源工具，需要自行加工处理。</p></blockquote><h1 id="3-RAG-实现"><a href="#3-RAG-实现" class="headerlink" title="3. RAG 实现"></a>3. RAG 实现</h1><p><img src="/img/2025-07-09-rag-basic/rag_workflow.png" alt="RAG 流程图"><span style="font-size: 12px;">Source: <a href="https://pub.towardsai.net/unlocking-the-advantages-of-semantic-chunking-to-supercharge-your-rag-models-d0daa61bab2c">Unlocking the Advantages of Semantic Chunking to Supercharge Your RAG Models</a></span></p><blockquote style="padding: 15px; border-radius: 10px; border-left: none; outline: 3px dotted darkslategray;">    <b style="color: orange;">RAG 流程</b>    <ul style="margin: 10px 0; padding-left: 1.5em;">        <li><b>数据预处理</b>：chunking -> embedding -> vector database        </li>        <li><b>用户提问</b>：embedding -> retrieve -> generation        </li>    </ul></blockquote><p>RAG 已经是 AI 领域一个相对成熟的架构了，有不少工具可以实现 RAG 的搭建，比如 LangChain &#x2F; LlamaIndex &#x2F; Haystack &#x2F; PydanticAI 等。这些工具可以一定程度上减轻开发 RAG 的工作量，方便对接不同的向量数据库，切换不同的底层 LLM。</p><p>实现 RAG 流程并不难，<span style="color: tomato;">难点在于 chunking 和 retrieve</span>，究竟选择怎样的策略才能使最终回复有更好的效果，这是做每个项目都要具体问题具体验证的。</p><h1 id="〰️✨结语✨〰️"><a href="#〰️✨结语✨〰️" class="headerlink" title="〰️✨结语✨〰️"></a>〰️✨结语✨〰️</h1><p>从本文叙述可以看出，RAG 这个 AI 架构是基于 AI 技术衍生出来的，但其实我们应用 RAG 做产品开发所需要下功夫的大多都不在 AI 上，可以说是源于 AI，又不只是 AI。</p><hr><span style="color: Gray;"><section class="footnotes"><div class="footnote-list"><ol><li><span id="fn:1" class="footnote-text"><span><a href="https://arxiv.org/abs/2307.03172">Lost in the Middle: How Language Models Use Long Contexts</a><a href="#fnref:1" rev="footnote" class="footnote-backref"> ↩</a></span></span></li></ol></div></section>]]></content>
    
    
    <categories>
      
      <category>Tech &amp; Life</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI Behind the Scenes</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>LLM应用💫不需要学AI，会调接口就行</title>
    <link href="/techlife/llm-application-basic.html"/>
    <url>/techlife/llm-application-basic.html</url>
    
    <content type="html"><![CDATA[<blockquote style="font-size: 14px;color: White; background-color: darkslategray; padding: 15px; border-radius: 10px; outline: 2px dotted darkslategray; outline-offset: 5px;">    <b style="font-size: 16px;">TL;DR</b>    <ul style="margin: 10px 0; padding-left: 1.5em;">        <li>现在发布的 LLM 都是预训练模型，可以通过 API 访问（即是触发 model inference），因此无需知道模型是怎么搭建的，会调接口就可以了。</li>        <li>接口设计 system / user / assistant role 来进行交互。</li>        <li>LLM 没有“记忆”，可以通过拼接历史对话来实现记忆功能。</li>        <li>接口提供的 function calling 功能可以自动触发指定任务，并且返回结构化输出，从而与下游任务交互。</li>        <li>“联网搜索”实际上是做了 2 次 inference，这种通过检索来优化 LLM 生成结果的手段，称为 RAG。</li>    </ul></blockquote><br><div style="text-align: center; font-size: 16px; color: gray;">    · · · · · ✦ ✧ ✦ · · · · ·</div><br><p>现在大众说到 AI<sup id="fnref:1" class="footnote-ref"><a href="#fn:1" rel="footnote"><span class="hint--top hint--rounded" aria-label="技术层面的 AI 和大众所说的 AI 有一定的差异。我发现很多民众会认为人脸识别、语音识别这些现在已经是司空见惯的成熟技术了，不是 AI。但其实这些也是 AI。">[1]</span></a></sup>，一般就是指基于 LLM（Large Language Model，大语言模型）搭建的 AI 对话产品。比如最先火起来并且一直在同领域领跑的 ChatGPT（OpenAI），它是一个基于 GPT 系列模型<sup id="fnref:2" class="footnote-ref"><a href="#fn:2" rel="footnote"><span class="hint--top hint--rounded" aria-label="GPT 模型并不是只有一个模型，而是有多个版本的模型，并且还在不断更新迭代。在 ChatGPT 面世之前，OpenAI 已经有 GPT-1 / GPT-2 / GPT-3 这几个版本。初次发行的 ChatGPT 是在 GPT‑3.5 上进行 fine-tune（微调）开发的 AI 对话产品，后续 ChatGPT 采取不同的订阅等级提供给用户不同的模型版本以及其他附加功能。其他 LLM 模型同理，也是系列模型，都在不断迭代中。">[2]</span></a></sup>搭建的智能对话产品。另外几个类似的热门产品有：DeepSeek（DeepSeek AI）、Gemini（Google）、Claude（Anthropic）等。这几个 AI 产品的命名与其底层的系列模型的名称都是一样的。</p><h1 id="1-LLM-飞入寻常百姓家"><a href="#1-LLM-飞入寻常百姓家" class="headerlink" title="1. LLM 飞入寻常百姓家"></a>1. LLM 飞入寻常百姓家</h1><p>LLM 这个概念源自 2017 年 Google 提出的 Transformer 架构。Transformer 的发明使得 NLP（Natural Language Processing，自然语言处理）<sup id="fnref:3" class="footnote-ref"><a href="#fn:3" rel="footnote"><span class="hint--top hint--rounded" aria-label="NLP（Natural Language Processing，自然语言处理）就是研究怎么用计算机去理解人类的语言。简单来说，计算机语言就是写代码，自然语言就是写文章。">[3]</span></a></sup>领域迎来重大突破。而 ChatGPT 的产品化，把 LLM 这项技术转化成了大众可用的工具。开发 ChatGPT 的公司 OpenAI 同时也发布了相关的 API，让开发者可以把 LLM 集成到自己的应用中。后续其他厂商的 LLM 模型发布都采取了 API 的形式，有一些所谓开源的模型还支持本地部署（比如 DeepSeek）。</p><p>造 LLM 这个轮子需要很高的硬件成本和人力成本，但研发的厂商把这些模型以 API 形式发布，对于使用者来说就很友好了。我们不需要考虑模型训练有什么硬件需求，模型训练的参数怎么调，用来训练的数据怎么收集，数据质量高不高，因为发布的这些模型已经训练好了。现在所发布的 LLM 都是<strong>预训练模型（pre-trained model）</strong>。</p><p>我们要使用这些 LLM 的时候就是开袋即食，和食用其他 API 是一样的。想要把 LLM 集成到我们的应用里，搞懂这个 API 怎么 request 和解析 response 就可以了，无需学会 LLM 模型的原理。正如我们使用冰箱不需要知道冰箱是怎么制冷的，知道分冷藏和冷冻就可以了。</p><p>这里以一路领跑的 OpenAI 为例，它奠定了 LLM 以 API 形式发布的基础，现在各大厂商都使用类似的方式发布模型，DeepSeek 甚至是直接设计了 OpenAI 的同款 API（Python SDK），让使用者可以无痛转换。了解了 OpenAI 的接口如何使用，市面上的 LLM 服务都可以适用。</p><h1 id="2-Model-Inference（模型推理）"><a href="#2-Model-Inference（模型推理）" class="headerlink" title="2. Model Inference（模型推理）"></a>2. Model Inference（模型推理）</h1><h2 id="2-1-API-调用"><a href="#2-1-API-调用" class="headerlink" title="2.1 API 调用"></a>2.1 API 调用</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># ...只展示主要code...</span><br>completion = client.chat.completions.create(<br>    model=<span class="hljs-string">&quot;gpt-4.1&quot;</span>,<br>    messages=[<br>        &#123;<br>            <span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>,<br>            <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;Write a one-sentence bedtime story about a unicorn.&quot;</span><br>        &#125;<br>    ]<br>)<br></code></pre></td></tr></table></figure><p>调用 API（<a href="https://platform.openai.com/docs/guides/text?api-mode=chat">OpenAI Chat Completions API</a>），就会触发 LLM 进行 inference（推理）生成文本。</p><p>必填参数2个：</p><ul><li><code>model</code>: 模型版本选择，GPT-3.5 或者 GPT-4 等等，具体模型型号查询：<a href="https://platform.openai.com/docs/models">OpenAI Models list</a></li><li><code>messages</code>:  传给模型的内容，文本内容以不同的 role 传给模型，role 设定见下文。</li></ul><h2 id="2-2-role-设定"><a href="#2-2-role-设定" class="headerlink" title="2.2 role 设定"></a>2.2 role 设定</h2><p>role 有 3 种取值：<font style="color:orange;">system, user, assistant</font></p><h3 id="“user”-用户-“assistant”-AI"><a href="#“user”-用户-“assistant”-AI" class="headerlink" title="“user” - 用户, “assistant” - AI"></a>“user” - 用户, “assistant” - AI</h3><p>以 user &#x2F; assistant 的角色来标记用户和 AI 的一问一答。以 <u>user role</u> 传入文本内容，得到 <u>assistant role</u> 的响应，也就是 LLM 的回复。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-comment">// input</span><br><span class="hljs-punctuation">&#123;</span><span class="hljs-attr">&quot;role&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;user&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;content&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;介绍一下你自己&quot;</span><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-comment">// output</span><br><span class="hljs-punctuation">&#123;</span><span class="hljs-attr">&quot;role&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;assistant&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;content&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;您好！我是由OpenAI开发的人工智能语言模型，名字是ChatGPT。我可以帮助回答各种问题，提供信息、写作建议、学习辅导、创意创作以及与您进行愉快的交流。我的知识截止到2023年10月，所以对那之后的最新事件可能了解有限。如果您有任何问题或需要帮助的地方，请随时告诉我！&quot;</span><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><h3 id="“system”-AI人设"><a href="#“system”-AI人设" class="headerlink" title="“system” - AI人设"></a>“system” - AI人设</h3><p><u>system role</u> 可以看作给 AI 自定义的人设，比如限定背景、身份、语言风格等。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-comment">// input</span><br><span class="hljs-punctuation">&#123;</span><span class="hljs-attr">&quot;role&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;system&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;content&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;你叫Hola，是一个资深商业咨询师，你可以为企业解答各种商业问题。&quot;</span><span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br><span class="hljs-punctuation">&#123;</span><span class="hljs-attr">&quot;role&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;user&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;content&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;介绍一下你自己&quot;</span><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-comment">// output</span><br><span class="hljs-punctuation">&#123;</span><span class="hljs-attr">&quot;role&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;assistant&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;content&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;您好，我是Hola，一名资深商业咨询师，专注于为企业提供战略规划、运营优化、市场发展、数字转型等方面的专业建议。拥有丰富的行业经验，曾协助多家企业实现业务增长和转型升级。我的目标是帮助企业识别机会、应对挑战，制定切实可行的解决方案，从而实现持续的成功和竞争优势。如有任何商业相关的问题，欢迎随时咨询！&quot;</span><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>可以看到对于用户同样的提问，添加了 system 人设后得到的回复就不一样了。所以集成到应用时可以在后台写好 system role 的定义，控制我们希望用户得到的回复。</p><p>再举个例子，我在调试一个文档对话demo的时候，尝试过不设定 system role，当用户问文档以外的通识性话题时，LLM 会照常给出回复。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-comment">// input</span><br><span class="hljs-punctuation">&#123;</span><span class="hljs-attr">&quot;role&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;user&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;content&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;介绍一下北京景山公园&quot;</span><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-comment">// output</span><br><span class="hljs-punctuation">&#123;</span><span class="hljs-attr">&quot;role&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;assistant&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;content&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;北京景山公园位于北京市中心的故宫博物院西侧，是一座历史悠久、景色优美的城市公园。公园始建于明朝永乐年间（1406年），原为皇家花园，后逐渐发展成为景观公园。景山公园占地面积约68,7公顷，以其巍峨的山丘和丰富的文化底蕴著称。\n公园的核心是景山，它是一座人工堆筑的古城山，高约44.7米，从山顶可以俯瞰整个紫禁城（故宫）和北京城市景观。登上景山顶，可以一览北京的壮丽景色，是游客拍照、欣赏城市全景的绝佳位置。\n除了景山之外，公园内还有许多亭台楼阁、古树名木和湖泊，景色四季各异。春天桃花盛开，夏季绿意盎然，秋天红叶满山，冬天则是银装素裹的景致。\n景山公园不仅是一个休闲娱乐的好去处，也是北京的重要历史文化遗迹之一。它与故宫、天安门广场等地相邻，成为游客体验北京古今交融的必访之地。&quot;</span><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>而在 system role 加上设定限制后，它就不会回复文档以外的内容了。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-comment">// input</span><br><span class="hljs-punctuation">&#123;</span><span class="hljs-attr">&quot;role&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;system&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;content&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;你是Smart Reading小助手，请根据用户提问，检索相关文件内容并回答问题。如果检索结果为空，或者检索结果与提问无关，请回答\&quot;抱歉，我无法在文档中找到相关内容。您可以上传相关文件，或者使用支持通用问答的AI助手。\&quot;&quot;</span><span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br><span class="hljs-punctuation">&#123;</span><span class="hljs-attr">&quot;role&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;user&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;content&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;介绍一下北京景山公园&quot;</span><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-comment">// output</span><br><span class="hljs-punctuation">&#123;</span><span class="hljs-attr">&quot;role&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;assistant&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;content&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;抱歉，我无法在文档中找到相关内容。您可以上传相关文件，或者使用支持通用问答的AI助手。&quot;</span><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>在搭建定制化的 AI 对话产品时，需要调的 prompt 主要就是 system role 里的描述。我们如果想要产品更专注于做我们设定范围的服务，在 system role 加限制就很重要。user role 里用户会如何 prompting 是无法限制的。</p><p>如果不是为了搭建 AI 对话，而是要实现某单一功能，设计 system role 和直接只用 user role 没有差别。比如客户评价的情绪识别，读取每条客户评价识别是积极还是消极，那么以下两种实现方式的效果是一样的。显然在这个应用场景里只用 user role 更简洁。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-comment">// input</span><br><span class="hljs-punctuation">&#123;</span><span class="hljs-attr">&quot;role&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;system&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;content&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;请识别客户评价的情绪，是积极还是消极&quot;</span><span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br><span class="hljs-punctuation">&#123;</span><span class="hljs-attr">&quot;role&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;user&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;content&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;&lt;客户评价文本&gt;&quot;</span><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-comment">// input</span><br><span class="hljs-punctuation">&#123;</span><span class="hljs-attr">&quot;role&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;user&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;content&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;请识别客户评价的情绪，是积极还是消极：&lt;客户评价文本&gt;&quot;</span><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><h2 id="2-3-上下文记忆"><a href="#2-3-上下文记忆" class="headerlink" title="2.3 上下文记忆"></a>2.3 上下文记忆</h2><p>如前面所说，市面上发布的 LLM 都是已经训练好的模型，所以我们做 inference 是不会改变模型的，模型也不会“记住”刚才问过的问题。虽然 LLM 没有“记忆”功能，但我们可以<strong>模拟记忆</strong>来实现多轮对话，把历史对话拼接起来传入 <code>messages</code>。</p><p>第一轮问：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-comment">// input</span><br><span class="hljs-punctuation">&#123;</span><span class="hljs-attr">&quot;role&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;system&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;content&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;你叫Hola，是一个资深商业咨询师，你可以为企业解答各种商业问题。&quot;</span><span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br><span class="hljs-punctuation">&#123;</span><span class="hljs-attr">&quot;role&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;user&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;content&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;介绍一下你自己&quot;</span><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>第一轮答：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-comment">// output</span><br><span class="hljs-punctuation">&#123;</span><span class="hljs-attr">&quot;role&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;assistant&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;content&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;您好，我是Hola，一名资深商业咨询师，专注于为企业提供战略规划、运营优化、市场发展、数字转型等方面的专业建议。拥有丰富的行业经验，曾协助多家企业实现业务增长和转型升级。我的目标是帮助企业识别机会、应对挑战，制定切实可行的解决方案，从而实现持续的成功和竞争优势。如有任何商业相关的问题，欢迎随时咨询！&quot;</span><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>第二轮问：把第一轮答拼接到第一轮问里，加上用户的新提问，传入 <code>messages</code></p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-comment">// input</span><br><span class="hljs-punctuation">&#123;</span><span class="hljs-attr">&quot;role&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;system&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;content&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;你叫Hola，是一个资深商业咨询师，你可以为企业解答各种商业问题。&quot;</span><span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br><span class="hljs-punctuation">&#123;</span><span class="hljs-attr">&quot;role&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;user&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;content&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;介绍一下你自己&quot;</span><span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br><span class="hljs-punctuation">&#123;</span><span class="hljs-attr">&quot;role&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;assistant&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;content&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;您好，我是Hola，一名资深商业咨询师，专注于为企业提供战略规划、运营优化、市场发展、数字转型等方面的专业建议。拥有丰富的行业经验，曾协助多家企业实现业务增长和转型升级。我的目标是帮助企业识别机会、应对挑战，制定切实可行的解决方案，从而实现持续的成功和竞争优势。如有任何商业相关的问题，欢迎随时咨询！&quot;</span><span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br><span class="hljs-punctuation">&#123;</span><span class="hljs-attr">&quot;role&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;user&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;content&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;我想要知道房地产行业的最新趋势和挑战&quot;</span><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>第二轮答：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-comment">// output</span><br><span class="hljs-punctuation">&#123;</span><span class="hljs-attr">&quot;role&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;assistant&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">&quot;content&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;您好，关于房地产行业的最新趋势与挑战，以下是一些关键点供您参考：\n\n一、最新趋势：\n1. 绿色与可持续发展：绿色建筑、环保材料和节能技术日益成为行业标准，推动房地产项目向可持续方向发展。\n2. 数字化转型：引入大数据、物联网、人工智能等技术，实现智慧物业管理、虚拟看房和精准市场分析。\n3. 押注二三线城市和郊区：随着一线城市房价上涨和购房限制放宽，更多投资流向二三线城市和城市郊区，带来新的增长点。\n4. 政策调控与市场深化：政府加强对房地产市场的调控，推动市场健康发展，注重房地产的租赁、共有产权等多样化形式。\n5. 住宅租赁市场崛起：租房市场不断规范，长租公寓和租购并举的模式促进住房多样化。\n\n二、主要挑战：\n1. 政策与调控风险：政府频繁出台限购、限贷等政策，影响市场预期和资金流动。\n2. 资金链压力：土地成本上升、融资环境收紧，对开发商资金链构成压力。\n3. 市场需求变化：随着人口结构变化和年轻一代购房观念转变，传统住宅需求减弱，市场格局调整。\n4. 经济不确定性：宏观经济波动可能影响购房者信心和市场活跃度。\n5. 技术引入与适应：行业需积极适应数字化转型，技术应用的成本和风险也考虑在内。\n\n总结：\n房地产行业正处于深刻变革中，绿色可持续、数字化和市场多元化是未来的主要方向，但政策变化和资金风险也不容忽视。企业可以通过提升技术应用、调整产品策略、关注政策动态等方式，应对行业的挑战，把握发展机遇。\n\n如果您需要更详细的行业分析或针对特定市场的建议，欢迎随时告诉我！&quot;</span><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>以此类推，以拼接的方式告诉模型之前聊过的内容，就可以实现“记住”历史对话。</p><p>在 ChatGPT &#x2F; DeepSeek 等对话产品界面，点击开启新对话就会“清空记忆”，点击历史对话就可以再续前缘。所以你跟 AI 说“忘掉我们之前说的吧”，其实它会把之前说的历史对话和这一句孟婆汤指令一起传入模型。只有点击开启新对话，才会<strong>真的</strong>忘掉往事。</p><h1 id="3-与下游交互"><a href="#3-与下游交互" class="headerlink" title="3. 与下游交互"></a>3. 与下游交互</h1><p>LLM 所实现的就只是文本生成，这很不智能。如果我们指令让 LLM 生成结构化数据，那不就可以传递给第三方系统进行交互了！</p><p>比如有住户跟物业管家说：</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs css">我是<span class="hljs-selector-tag">B</span>栋<span class="hljs-number">1103</span>的王先生，我家厨房水管爆了，水漏得很厉害，请赶快派人来修！<br></code></pre></td></tr></table></figure><p>我们让 LLM 从中提取相关信息，以 JSON 格式回复：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;resident_name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;王先生&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;room_number&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;B栋1103&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;repair_type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;水电&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;description&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;厨房水管爆了，水漏得很厉害&quot;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>然后把这个 JSON 传给物业报修系统去生成一个报修单。</p><h2 id="Function-calling"><a href="#Function-calling" class="headerlink" title="Function calling"></a>Function calling</h2><p>OpenAI 接口的 <a href="https://platform.openai.com/docs/guides/function-calling?api-mode=chat"><strong>Function calling</strong></a> 功能可以实现这个目的。除了 <code>model</code> 和 <code>messages</code> 这两个必填参数，再在 <code>tools</code> 参数里传入以下信息：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 定义tool</span><br>repair_order_tool = &#123;<br>    <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;function&quot;</span>,<br>    <span class="hljs-string">&quot;name&quot;</span>: <span class="hljs-string">&quot;create_repair_order&quot;</span>,<br>    <span class="hljs-string">&quot;description&quot;</span>: <span class="hljs-string">&quot;根据住户提供的报修信息生成维修工单&quot;</span>,  <span class="hljs-comment"># tool定义（GPT会根据描述自动识别触发）</span><br>    <span class="hljs-string">&quot;parameters&quot;</span>: &#123;<br>        <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;object&quot;</span>,<br>        <span class="hljs-string">&quot;properties&quot;</span>: &#123;     <span class="hljs-comment"># 参数定义（执行调用时可能会传入的参数）</span><br>            <span class="hljs-string">&quot;resident_name&quot;</span>: &#123;<br>                <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;string&quot;</span>, <br>                <span class="hljs-string">&quot;description&quot;</span>: <span class="hljs-string">&quot;住户姓名&quot;</span>   <span class="hljs-comment"># 描述该参数（GPT会根据描述自动提取对应参数）</span><br>            &#125;,  <br>            <span class="hljs-string">&quot;room_number&quot;</span>: &#123;<br>                <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;string&quot;</span>, <br>                <span class="hljs-string">&quot;description&quot;</span>: <span class="hljs-string">&quot;房号，如A栋502&quot;</span><br>            &#125;,<br>            <span class="hljs-string">&quot;repair_type&quot;</span>: &#123;<br>                <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;string&quot;</span>,<br>                <span class="hljs-string">&quot;enum&quot;</span>: [<span class="hljs-string">&quot;水电&quot;</span>, <span class="hljs-string">&quot;家电&quot;</span>, <span class="hljs-string">&quot;门窗&quot;</span>, <span class="hljs-string">&quot;其他&quot;</span>],<br>                <span class="hljs-string">&quot;description&quot;</span>: <span class="hljs-string">&quot;报修问题类型&quot;</span><br>            &#125;,<br>            <span class="hljs-string">&quot;description&quot;</span>: &#123;<br>                <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;string&quot;</span>, <br>                <span class="hljs-string">&quot;description&quot;</span>: <span class="hljs-string">&quot;问题的详细描述&quot;</span><br>            &#125;,  <br>        &#125;,<br>        <span class="hljs-string">&quot;required&quot;</span>: [<span class="hljs-string">&quot;room_number&quot;</span>, <span class="hljs-string">&quot;repair_type&quot;</span>, <span class="hljs-string">&quot;description&quot;</span>]   <span class="hljs-comment"># 定义必须提供的参数</span><br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>定义这个 tool 是用来做什么的（”description”: “根据住户提供的报修信息生成维修工单”），LLM 就会根据这个描述来判断是否要触发 function calling。”parameters” 里定义每个参数的含义（每个 parameter 的 description），LLM 就会把对应的参数值抽取出来，得到以上 JSON 格式的结果。</p><p>支持设置多个 tool，LLM 会自动判断应该触发哪个或哪几个 tool。另外一个相关的参数 <code>tool_choice</code>，可以指定必须触发某个 tool。</p><p>不难想象，在 ChatGPT &#x2F; DeepSeek 等对话产品界面，“联网搜索”这个功能就可以通过这种方式来实现。用户打开联网搜索按钮，则指定触发联网搜索这个 tool（第一次 inference），去调用搜索引擎 API，然后把搜索结果传回给 LLM，LLM 就会基于搜索结果生成回复（第二次 inference），用户就可以得到最新信息了。现在 OpenAI 是直接提供 <a href="https://platform.openai.com/docs/guides/tools-web-search?api-mode=chat">Web search</a> 这个功能，不需要通过写 Function calling 来搭建。</p><h1 id="4-与上下游交互"><a href="#4-与上下游交互" class="headerlink" title="4. 与上下游交互"></a>4. 与上下游交互</h1><p>如上文所说，联网搜索功能的实现，在一次对话中其实进行了2次 inference。</p><ul><li><p>第一次 inference：LLM 从用户提问内容中抽取搜索内容，把搜索内容给搜索引擎进行搜索；</p><p>  <img src="/img/2025-06-30-llm-application/bing-openai-gpt-4-1678815799.jpg"></p><p>  从当初 Bing Chat 界面的截图来看，用户提问的是 <i>“does bing use gpt-4?”</i>，而所显示的中间步骤 Searching for 搜索内容是 <i>“bing gpt-4”</i>，可见并不是直接把用户提问直接进行搜索，是用 LLM 识别出用来搜索的关键词再进行搜索的。现在市面上的对话产品都没有显示搜索关键词这个中间步骤了，包括现在又变成叫 Copilot 的 Bing Chat 也没有设计显示搜索关键词。</p></li><li><p>第二次 inference：让 LLM 基于搜索结果回答用户的提问，把 LLM 生成的回复返回给用户。</p>  <figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs markdown"><span class="hljs-section"># 取到搜索结果后，传给LLM的prompt</span><br><br>你是一位智能助手。请根据以下搜索结果回答用户的问题，并在回答中使用对应的编号注明信息来源。<br><br>搜索结果：<br><br><span class="hljs-bullet">1.</span> [标题/链接] — 摘要<br><span class="hljs-bullet">2.</span> [标题/链接] — 摘要<br><span class="hljs-bullet">3.</span> [标题/链接] — 摘要<br><br>用户问题：<br>&lt;用户的原始提问&gt;<br><br>回答：<br></code></pre></td></tr></table></figure></li></ul><p>第一次 inference 是 LLM 与下游任务（调用搜索引擎）的交互，第二次 inference 是 LLM 与上游任务（搜索得到结果）的交互。</p><p>这种通过检索来优化 LLM 生成结果的手段，称为 <strong>RAG（Retrieval-Augmented Generation，检索增强生成）</strong>。</p><h2 id="RAG-架构"><a href="#RAG-架构" class="headerlink" title="RAG 架构"></a>RAG 架构</h2><p>RAG 这个概念在 2020 年提出，通过引入外部知识库，解决了预训练模型知识访问受限、难以更新知识、缺乏可解释性等问题。在 ChatGPT 发布后不久，RAG 架构迅速成为热点。现在 RAG 在业界已经是很常见的实现方式了。关于 RAG 的具体原理和实现细节，详见另一篇 blog《<a href="/techlife/rag-concept.html" title="RAG架构💫源于AI，不只AI">RAG架构💫源于AI，不只AI</a>》。</p><h1 id="〰️✨结语✨〰️"><a href="#〰️✨结语✨〰️" class="headerlink" title="〰️✨结语✨〰️"></a>〰️✨结语✨〰️</h1><p>至此，LLM 原生 API 常用的能力基本梳理完毕。归根结底，LLM 只有一种输出，就是文本。<sup id="fnref:4" class="footnote-ref"><a href="#fn:4" rel="footnote"><span class="hint--top hint--rounded" aria-label="此文未讨论多模态的生成模型，仅讨论输入输出都是文本的 LLM。">[4]</span></a></sup>我们看到的各种 RAG、Agent 等高级玩法，都是基于 LLM 生成的文本把各种工具串起来所搭建的。</p><p>大致了解原生 API 的基本能力后，可以把学习重点转向 LangChain &#x2F; LlamaIndex &#x2F; Haystack &#x2F; PydanticAI 等 AI 框架，这些框架已经封装了上下文记忆、历史对话存储、RAG 通用流程等多种常用功能。</p><p>至于从零训练一个 LLM 模型，那是属于少数顶级技术团队才能完成的大工程，我们关注各大厂商的竞逐即可。</p><hr><span style="color: Gray;"><section class="footnotes"><div class="footnote-list"><ol><li><span id="fn:1" class="footnote-text"><span>技术层面的 AI 和大众所说的 AI 有一定的差异。我发现很多民众会认为人脸识别、语音识别这些现在已经是司空见惯的成熟技术了，不是 AI。但其实这些也是 AI。<a href="#fnref:1" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:2" class="footnote-text"><span>GPT 模型并不是只有一个模型，而是有多个版本的模型，并且还在不断更新迭代。在 ChatGPT 面世之前，OpenAI 已经有 GPT-1 &#x2F; GPT-2 &#x2F; GPT-3 这几个版本。初次发行的 ChatGPT 是在 GPT‑3.5 上进行 fine-tune（微调）开发的 AI 对话产品，后续 ChatGPT 采取不同的订阅等级提供给用户不同的模型版本以及其他附加功能。其他 LLM 模型同理，也是系列模型，都在不断迭代中。<a href="#fnref:2" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:3" class="footnote-text"><span>NLP（Natural Language Processing，自然语言处理）就是研究怎么用计算机去理解人类的语言。简单来说，计算机语言就是写代码，自然语言就是写文章。<a href="#fnref:3" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:4" class="footnote-text"><span>此文未讨论多模态的生成模型，仅讨论输入输出都是文本的 LLM。<a href="#fnref:4" rev="footnote" class="footnote-backref"> ↩</a></span></span></li></ol></div></section>]]></content>
    
    
    <categories>
      
      <category>Tech &amp; Life</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI Behind the Scenes</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>IT行业的数据“微泄露”</title>
    <link href="/techlife/data-boundary.html"/>
    <url>/techlife/data-boundary.html</url>
    
    <content type="html"><![CDATA[<p>最近迷上了在贝壳上看房源VR，看到一些有趣的信息会跟朋友们分享一下。好友群里有一个素未谋面的同城网友，每次都跳出来表热心，说自己有手段能查到房子有没有问题。当我再次分享房源截图给朋友们看看聊聊，他又跳出来说房源发他查查。我表示并不打算买，只是看到这个房一开始开价过高后面屡次降价，分享出来给大家看看行情，阻止他又开始无脑劝说。结果此举激发了他开启疯狂输出：错，你没懂我在说什么，我说我能查到隐情。😓😓😓😓😓</p><p>此人在体制内IT相关岗位工作，在根本没有人询问的情况下，屡次借话题暗示自己有权限从公安系统查到个人数据。<strong>这种以职务之便侵犯公民个人信息的行为是违法的。</strong>更可耻的是拥有权限的人没有任何保密意识，甚至还热衷于向别人炫耀特权。</p><p>此人被逼急开始在群聊里明确表示自己能查到个人信息，引来了几位群友的关注，询问是否真的可以查到相关信息。很多人会被这样的特权所吸引，希望自己可以从中获利。但其实细想一下，这是一个大大的red flag。他并不觉得暴露他人隐私有什么不妥，不以窥探他人隐私为耻，反而拿来当谈资。这意味着我们群友的信息，也可能随时被他“随手一查然后分享给别人”。真正可怕的不是权限本身，而是掌握权限的人没有职业操守。</p><p>他或许觉得，反正身边人也在这么干，我又没有贩卖信息，这没什么问题啊。这真的没问题吗？</p><p>宁波有一个案件，一位民警应别人要求查询了公民个人信息，将一位女士的住址告知对方，导致这位女士被前男友杀害。</p><blockquote><p>新闻来源：<a href="https://mp.weixin.qq.com/s/7Y70Tv5Yyn_jpc2vlPyDVQ">违规帮忙查住址引发感情命案，民警被判缓刑</a></p></blockquote><p align="center">  <img src="/img/2025-06-18-data-boundary/data_1.jpg" width="40%"></p><p>詹某以权谋私利的时候，或许他想的也是“我只是透露一些信息而已，没什么问题啊”，他也没料到会造成这种严重的后果。</p><p>在互联网时代，只要我们上网就存在信息被泄露的风险。这次我差点被动成为侵害者的同谋，曾几何时我也是受害者。</p><p>几年前刚入职时有一位同事来跟我打招呼，说这里大多数都是我的同龄人，很好相处。对方这句套近乎的话使我内心警铃大作，我的个人信息被泄露了！我所入职的正是公司的数据中心，而这位热心人士与数据组的主管相交甚好，无话不谈。可想而知每位新同事都会被悄悄“起底”，作为他们茶余饭后的谈资。其后我也亲眼目睹了团队里某位数据工程师在看到部门有新同事入职时，熟练地打开SQL查询新同事的个人信息，并且企图与我分享交谈。</p><p>他们对团队成员的八卦有没有影响到当事人，这个不好评判。但是作为曾经的受害者，我是觉得不被尊重的。</p><p>“无心”的炫耀、“顺手”的查询、“无害”的闲聊，这些看似没什么大不了的个人信息泄露，模糊了人对隐私的敬畏。</p><p>你永远无法预知，今天被拿来八卦的那一行信息，明天会不会成为伤害你的工具。</p><p>行业相关的各位同行们，面对你所拥有的数据查询权限，你的底线会是什么呢？</p>]]></content>
    
    
    <categories>
      
      <category>Tech &amp; Life</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>I. 人生终极目标……之一</title>
    <link href="/journey/north-europe-aurora-1.html"/>
    <url>/journey/north-europe-aurora-1.html</url>
    
    <content type="html"><![CDATA[<h1 id="❧-好想好想看看世界另一端的极光"><a href="#❧-好想好想看看世界另一端的极光" class="headerlink" title="❧ 好想好想看看世界另一端的极光"></a>❧ 好想好想看看世界另一端的极光</h1><p>很多人都听过张韶涵的《欧若拉》这首歌，我是从这首歌知道有aurora，中文叫“极光”的东西。但是生活在广东，一个冬天最低气温0°C以上的地区，什么北极圈什么极光对我来说就是世界遥远的另一端。</p><p>后来读书在巴黎住过一段时间，每年圣诞假期都会被北欧极光团的广告吸引。但是真的好贵，上学还花着父母的钱也不好意思做这种娱乐性质的高额消费。眼看着极光团一年比一年贵，看着看着我都结束学业回国了，回到了广州居住，极光就离我更遥远了。</p><p><img src="/img/2025-06-aurora/20250605_01_aurora_dream.jpg" alt="回国了还每年在“想看极光要看极光”，不查回聊天记录都不知道自己意愿这么强烈😆"></p><h1 id="❧-我要闷声做大计"><a href="#❧-我要闷声做大计" class="headerlink" title="❧ 我要闷声做大计"></a>❧ 我要闷声做大计</h1><p>COVID-19阻止了旅行，我每年一游的计划戛然而止。封禁前两年也没什么出门游玩的心情，后面国外基本放开不限制通行了，在网上陆续刷到有人在北欧看到极光大爆发，越来越坐不住了。终于在22年11月底我们也解禁了，出境旅游的苗头熊熊燃起！开始研究独自去极光之旅的可行性。</p><p>没错，从一开始我就打算solo trip。考虑到办签证的难度、对北欧高物价的接受度和要有十天以上的长假期这几个因素，我想不到身边有哪个朋友合适。我不希望这个大project受到别人的干扰，我必须成行！我要闷声做计划！</p><h1 id="❧-雄心壮志中的丝丝犹豫"><a href="#❧-雄心壮志中的丝丝犹豫" class="headerlink" title="❧ 雄心壮志中的丝丝犹豫"></a>❧ 雄心壮志中的丝丝犹豫</h1><p>虽说我立下了雄心壮志要独自前往北欧，但也存在着各种各样的担忧。</p><p>我不是经验丰富的独行者，大部分过去的旅行都是有朋友同行。作为常年生活在亚热带的人，我难以想象在苦寒之地怎么生活。唯一一次遇到大雪纷飞，是多年前圣诞假期跟团去德国玩。好歹德国在我认知中还属于“正常人类居住的地方”，而北欧，在我的概念里就是“发配宁古塔”，我一个南方人往前走分分钟是九死一生！描述是夸张了一点，可见这个旅行在我看来真的是一个巨大的挑战。</p><p>我问了自己两个问题：</p><p><b><span style="color:Red;"><code>Q1</code></span> 北欧旅行花费很高，是不是应该多攒点钱晚几年再去？</b></p><blockquote><p>这个问题我很快就有了答案。别再犹豫，就是现在，当下就去！第一，我的存款是足以支撑这趟旅行的，不至于为了这趟旅行我就要节衣缩食，甚至赊借度日，而且钱花掉了可以再赚。第二，我家里上一辈当前的身体状况不需要我随时守候，我也暂时没有下一辈需要照顾，万一再晚几年，家里对我的需求度很高，我没法出远门，如果我错过了这个本来可以实施的计划，将会成为我心里很大的遗憾。</p></blockquote><p><b><span style="color:Red;"><code>Q2</code></span> 当地的天气状况是超出我的认知范围的，是不是还是找个朋友做伴比较好呢？</b></p><blockquote><p>这个问题其实在我做攻略的时候还会不断出现在我脑海里。一个很客观的事实是，工作之后和朋友是很难对得上时间约在一起的。加上我的同龄人里有一半已婚或者已育，单身的朋友中对旅行有兴趣的也不多，喜欢旅行的朋友大部分对于要办签证出国是有点望而却步的，而且办理申根签证确实是一件麻烦事。这句话说了很多遍，但这里还是要吐槽一句，一生要办签证的中国人啊！总之，做好功课，做足准备，不要让未知的恐惧限制了自己。</p></blockquote><h1 id="❧-怂人的超长前摇——准备时长超过一年"><a href="#❧-怂人的超长前摇——准备时长超过一年" class="headerlink" title="❧ 怂人的超长前摇——准备时长超过一年"></a>❧ 怂人的超长前摇——准备时长超过一年</h1><p>要在冬天长假去北欧，那最可行的日子规划就是春节假期凑上年假。都说极光可遇不可求，我想要尽量待久一点，某种程度上加大几率。</p><p>22年年底放开，23年的春节假期我是没这么快赶上可以立马起行啦，我目标就定在24年春节。23年头两个月我就在关注各种追光团，研究如果要报24年同期的团究竟要提早多久比较好。</p><p>23年在家过了一个没有出门的五一假期，十一假期就坐不住了，新加坡我来啦！此行除了刷新我的旅行地图，是带有其他目的的，就是为我更长途的solo trip预热。</p><p>此前算下来有1.5次的solo trip经验。那0.5次是自己去比利时的首都布鲁塞尔，不过当时是住在法国北部的大城市里尔，在朋友家借宿，从里尔坐火车四十几分钟就可以到布鲁塞尔，当天来回。这个旅程说起来也有段故事，我出行前在巴黎被偷了手机，所以在布鲁塞尔我是没有手机导航，全靠一张简易的纸质地图和我手写的攻略探索这个城市。那1次就是疫情时趁大家都不敢出门头铁去了厦门，电脑都带上了，做好最坏打算被禁足在厦门。也是这次让我发现solo trip是多么的自由自在。</p><p>新加坡之行让我感觉出国旅行还算在我舒适圈里的，磕巴英语在旅行交流是完全够用的。我还复盘了一下我的个人出游行李清单，怎么收拾适合我的使用习惯又节省空间。</p><h1 id="❧-法签曲线救我"><a href="#❧-法签曲线救我" class="headerlink" title="❧ 法签曲线救我"></a>❧ 法签曲线救我</h1><p>就在23年底我正愁年假不够用和挪威签证不好申的时候，出了一则利好消息：法国对拥有法国硕士学位的中国人可发放五年多次的旅行签证。法国签证本来在申根区众多国家中算成功率比较高的了，再加上这个政策，我已经可以预见我的护照上即将贴上五年法签！</p><p>24年的春节前，大概1月底的时候，在TLS网站约递签最早已经只能约到3月1日了。别人说要提前半年准备递签，真的毫不夸张。我准备了学位证书还有成绩单证明自己在法国上过学并且获得了法国的硕士学位，还写了一封动机信深切地表达我的法兰西之情。（此处鸣谢ChatGPT，大大减轻写法语动机信的痛苦，以前留学的时候怎么就没遇上这种神器呢~）</p><p>从递签到出签，仅需3个工作日！这非常不法式，but I like it!</p><p>申根签的使用规则是首次入境需从发签国进入或者是在发签国逗留时间最长。那么如果首次不是从发签国入境，就需要提供在该国逗留时间最长的证明。为了避免这种麻烦，我计划先回一趟法国“激活”我的法签。下一次入境申根直接从北欧四国进入就妥啦！</p><p>然后我就走了一趟法瑞solo trip，十一天的行程，一个30L背包搞定！我对怎么收拾自己的行李已经有自己的最优解决方案了！</p><p>PS：时隔一年了，还是很记得瑞士日内瓦湖的美景有多么叹为观止！</p>]]></content>
    
    
    <categories>
      
      <category>Journey</category>
      
    </categories>
    
    
    <tags>
      
      <tag>我的极光大project</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>那年孔雀没开屏</title>
    <link href="/moments/zoo-memory.html"/>
    <url>/moments/zoo-memory.html</url>
    
    <content type="html"><![CDATA[<p>今天晚上约了在省中医做脚踝MR，没想到现在医院连晚上都能做检查了，确实方便了平时难请假的打工人。不过对医生来说，这恐怕不是什么好事。</p><p>躺在圆滚滚的机器里听了十分钟的噪音就照完了。医生简单说了两句是有炎症。我看他又着急安排下一个病人检查就不好细问，反正会出报告，之后还得约门诊医生复诊。我就去医院门口的公交站坐车回我的小窝。</p><p>上车坐下来一会儿，突然车窗上一个可爱的熊猫贴纸吸引了我的注意。贴纸上写着“大熊猫叫声”，旁边还有个二维码。</p><p><img src="/img/2025-06-04-zoo-memory/20250604_01_bus_zoo.jpg"></p><p>我拿出手机扫码打开了一个视频，画面是两只熊猫照片，声音是咿咿呀呀的熊猫叫声。哇，那一刻真的被可爱到融化。可爱的是熊猫，可爱的是熊猫的叫声，可爱的是这一刻的偶遇。❤️</p><p>我环顾车厢，发现原来这是广州动物园的宣传。车上的小幅横屏在播放着广州动物园的视频。车上贴满了广州动物园的广告。其他车窗也贴了不同小动物的叫声二维码。上车的乘客陆续发现这些小彩蛋，也有人像我一样掏出手机扫码听动物叫声。</p><p><img src="/img/2025-06-04-zoo-memory/20250604_02_bus_zoo.jpg"></p><p>上小红书搜了一下发现，原来我坐上的这趟是广州动物园痛车<sup id="fnref:1" class="footnote-ref"><a href="#fn:1" rel="footnote"><span class="hint--top hint--rounded" aria-label="“痛车”一词来源于日文“痛車（いたしゃ）”，指贴满动漫角色等二次元元素的车子，视觉效果强烈。类似的还有“痛包（痛バッグ）”“痛伞（痛傘）”“痛鞋”等，把喜欢的角色装饰在日常物品上。">[1]</span></a></sup>！一汽巴士和动物园联名的专线。官方宣传视频主打的是广州人的回忆杀，动员大家分享自己和广州动物园的故事。都是老广回忆呀，跟我这个外地人好像没什么关系。</p><p>看完宣传视频放下手机，继续放空欣赏车里的可爱动物。忽然想起来，不对呀，我小时候也是去过广州动物园的！</p><p>在我很小的时候，具体几岁就不记得了，应该还是小学生吧。想不起来我是怎么认识了孔雀这种动物，就吵着要看孔雀。我好想看看孔雀开屏究竟有多美。我们老家是十八线小城市，没有动物园。市中心有一个公园，我记得里面关着几只猴子，没别的动物了。</p><p>那时候我舅已经从老家搬到广州定居，我放假的时候会到广州找舅舅玩。大人们为了满足我的孔雀愿，带我去了广州动物园看孔雀。也不知道当时动物园里是没有孔雀，还是我们没有找到。总之是失望而回了。</p><p>后来我们又去了长隆动物世界，我还是满心期待地找孔雀。结果大人们指着两只秃尾巴的大鸟告诉我，这就是孔雀。我才不懂什么雌孔雀雄孔雀的，这哪里是孔雀啊，别说开屏了，尾巴都是秃的，丑死了。反正呢，我也接受了孔雀开屏是可遇不可求的。看来我从小就习惯躺平。</p><p>当然现在我已经见过孔雀开屏了，绿孔雀见过，白孔雀也见过。我也知道秃尾巴的也是孔雀了。我记不清都在哪里见过的这些孔雀开屏，倒是还记得小时候两次寻找孔雀开屏的失落。</p><p>人生不得意事十常八九。当时当刻的求而不得，或许将来的某一刻会杳然而至呢。当年暑假来广州当游客的小女孩也没想过自己会在广州定居吧。</p><hr><span style="color: Gray;"><section class="footnotes"><div class="footnote-list"><ol><li><span id="fn:1" class="footnote-text"><span>“痛车”一词来源于日文“痛車（いたしゃ）”，指贴满动漫角色等二次元元素的车子，视觉效果强烈。类似的还有“痛包（痛バッグ）”“痛伞（痛傘）”“痛鞋”等，把喜欢的角色装饰在日常物品上。<a href="#fnref:1" rev="footnote" class="footnote-backref"> ↩</a></span></span></li></ol></div></section>]]></content>
    
    
    <categories>
      
      <category>Moments</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Born This Way, Living My Way</title>
    <link href="/moments/lady-gaga-living-my-way.html"/>
    <url>/moments/lady-gaga-living-my-way.html</url>
    
    <content type="html"><![CDATA[<p>The first time I saw Lady Gaga, was in the TV series <em>Gossip Girl</em>. I can’t quite tell the details of that episode. All I can remember is her sharp red dress and the dramatic makeup. It was a MV rehearsal.</p><p>At the time, I thought, “What a weird performance. But the song is fabulous.” Curious about this artist, I looked up her name: <strong>Lady Gaga</strong>. A weird name.</p><p><em>WEIRD</em> - My very first impression about Lady Gaga.</p><p>But somehow, that weirdness caught my attention.</p><p><em>Bad Romance</em>, the song performed in the TV series, the first Lady Gaga track I ever heard, and the one that made me a fan, a Little Monster.</p><p>She went viral in the pop music world. I followed everything about her—albums, music videos, live shows, interviews.</p><p>I like her music, which tells the spirit of strong, brave and confidence. Her performance has an intense vibe, but she’s so gentle and calm in interviews. She’s quite different on and off stage.</p><p>I had watched all her shows online but never considered seeing an American pop star perform live, until I saw her tour poster at Zénith de Paris, the same arena where I had just attended Eason Chan’s concert. It’s a pity that I didn’t have any friends interested in her music, and at that time, I didn’t have the courage to attend a concert alone.</p><p>Last year, while planning my travels around the world, I made up my mind that I had to see her live.</p><p>This year, her Singapore show is right within my reach. Over the past few years, I’ve traveled the world alone and have visited Singapore twice, becoming somewhat familiar with the city. I feel ready and energized to attend her concert by myself this time. However, I’ve decided to prioritize saving for an apartment instead. So, I gave up on the idea from the very start.</p><p>I regret missing the chance 11 years ago, but this time, I feel no disappointment. I know exactly what I want to do. To me, Lady Gaga’s spirit is all about embracing who we truly are and living life on our own terms. If I were to meet her in person and tell her about my decision, I believe she would appreciate it.</p>]]></content>
    
    
    <categories>
      
      <category>Moments</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>我既是母亲，也是我自己</title>
    <link href="/moments/mothers-day.html"/>
    <url>/moments/mothers-day.html</url>
    
    <content type="html"><![CDATA[<p>今年母亲节看到一个老同学发的朋友圈，配文<em>『我们不止是孩子的妈妈，也要有自己的精彩人生🔅ᵕ̈ 祝你我快乐』</em>。</p><p>我发现我身边同龄或者稍微年长的“妈妈们”活得各有各的精彩。有的妈妈挤时间提升专业知识，没有因为孩子停止专业追求。有的妈妈为了方便带娃阶段性转换工作，没有因为孩子放弃职场。有的妈妈不爱做饭就给孩子点外卖，没有因为孩子没苦硬吃。有的妈妈工作认真负责，没有因为孩子多病要经常请假就推脱工作。</p><p>当这一代人成为母亲，越来越多的女性会有这样的意识，母亲只是我众多身份当中的一个。<strong>我既是母亲，也是我自己。</strong></p><p>在网上看到一段触动人心的小故事。网友的妈妈在母亲节说感谢女儿，因为女儿所以她有了母亲这个身份，觉得自己成为母亲是很骄傲的事。</p><p>成为母亲，是我的选择，而不是迫于社会压力。我不需要通过宣扬母亲的苦难来抵消被迫生儿育女的伤害。</p><p>愿生活在这个时代的我和我的女性朋友们，成为母亲是自己的伟大选择。</p>]]></content>
    
    
    <categories>
      
      <category>Moments</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>好东西，就这？</title>
    <link href="/feed/her-story.html"/>
    <url>/feed/her-story.html</url>
    
    <content type="html"><![CDATA[<p>五一放假在家终于看了之前大热的电影《好东西》。</p><p>两位女主非常养眼，视觉效果相当的赏心悦目。钟楚曦饰演的小叶，乐队主唱，一个寻爱寻到海王的单身姑娘，为了和对方保持联系，谎称自己已婚有孩假装潇洒。宋佳饰演的王铁梅，前记者现任自媒体编辑，离异带女儿，和小叶做了邻居，前夫经常来纠缠复合，和新认识的年轻弟弟保持肉体关系。叙事风格平淡，剧情很平实没有什么波澜，就好像是听了一个没什么八卦价值的邻里小事。</p><p>不过当中的一些小情节有引发到我的共鸣。<strong>什么是好东西？能让你开心的就是好东西。</strong></p><p>我爸老喜欢质问我，你做这个东西有什么意义？打游戏有什么意义？看剧有什么意义？怎么就没意义了，能愉悦我，这就是它的意义！</p><p>之前在社交媒体上屡次刷到这部电影的好评，观影者都给它加上了时下正盛行的“女性主义”标签。女性主义在当今中国的社交媒体是一个相当热门的社会议题。</p><p>什么是女性主义，如何定义女性主义，我暂时还没找到一个明确的答案。我能肯定的是，《好东西》这部电影，和<strong>女性主义</strong>毫无关系。电影只是平铺直述了两位女性的困境，没有展开解读，也没有总结拔高，找不到任何触动点。我会把它归类为<strong>中年疼痛文学</strong>。把它和女性主义扯上关系，甚至打上了女性主义代表作的标签，就和电影里前夫哥生搬女性主义词汇一样令人尴尬到脚趾抠地。</p><p>不知道电影宣传的时候有没有打着女性主义的旗号，还是后期被媒体冠上的虚名，反正在我观影过程中从头到尾都没有发现导演有表达女性主义这个意图。</p><p>我很困惑当我们谈到女性成长、女性觉醒、女性主义这些话题，大家很喜欢塑造“离开男人也能很精彩”的独立女性形象，比如电影里两位女主的人设。刻意牵扯男性而言的“独立”，我总觉得哪里不对劲。</p>]]></content>
    
    
    <categories>
      
      <category>Feed</category>
      
    </categories>
    
    
  </entry>
  
  
  
  
</search>
